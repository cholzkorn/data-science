library(tidyverse)
library(coin)
library(rpart)
library(cluster)
library(randomForest)
library(modelr)
library(caret)
# ---- LOAD THE DATA ------------------------------------------------------------------------------- #
df <- read_csv("C:/Users/Clem/OneDrive/Informatik_Lernen/Statistics/SampleProjects/Prediction_Marketing/marketing.csv")
df
# ---- DATA TRANSFORMATION ------------------------------------------------------------------------- #
# convert the variables to meaningful types
# AgeOfStore and SalesInThousands can be left as numbers
# MarketID, MarketSize, LocationID and Promotion make the most sense as factor
df$MarketID <- as.factor(df$MarketID)
df$MarketSize <- as.factor(df$MarketSize)
df$LocationID <- as.factor(df$LocationID)
df$Promotion <- as.factor(df$Promotion)
df$week <- as.factor(df$week)
# ---- DATA EXPLORATION ---------------------------------------------------------------------------- #
# Since we are interested in the prediction of sales, we want to plot the different variables against
# the sales. To get a quick overview, we can use facets.
# In our first facet, we see that promotions tend to work equally well in different markets
ggplot(data = df) +
geom_boxplot(mapping = aes(x = Promotion, y = SalesInThousands, color = Promotion)) +
facet_wrap(~ MarketSize, nrow = nlevels(df$MarketSize)) +
theme(legend.position="none") +
coord_flip()
# For this we have to merge
by_promotion <- group_by(df, Promotion)
Promotion_means <- summarize(by_promotion, pm_means = mean(SalesInThousands, na.rm = TRUE))
Promotion_means
# As we have seen from the medians in the previous graph, promotion 2 seems to perform worse
# than 1 or 2
# We can use a test to identify if the difference in means is significant
# For this, we have to merge promotion 1 and 2 into 1
grouped_promotion <- df$Promotion
grouped_promotion[grouped_promotion == "2"] <- "1"
grouped_promotion
prom_meantest <- as.tibble(cbind(df$SalesInThousands, grouped_promotion))
prom_meantest$grouped_promotion <- as.factor(prom_meantest$grouped_promotion)
t.test(V1 ~ grouped_promotion, data = prom_meantest)
# We can not reject our hypothesis that promotion 2 performs worse than the other groups combined
# In the another facet, we see that the influence of weeks on Sales might be very small.
ggplot(data = df) +
geom_boxplot(mapping = aes(x = week, y = SalesInThousands, color = week)) +
facet_wrap(~ MarketSize, nrow = nlevels(df$MarketSize)) +
theme(legend.position="none") +
coord_flip()
# In this next plot we can see that the age of the store does not have a clear impact
# on sales
ggplot(data = df, aes(x = AgeOfStore, y = SalesInThousands)) +
geom_point() +
geom_smooth()
# The main influence on sales seems to be the market size
ggplot(data = df, aes(x = MarketSize, y = SalesInThousands)) +
geom_boxplot()
# Accordingly, we calculate the means and medians of Sales, grouped by MarketSize
# and we see that the mean, as well as the median, differ greatly, with large markets
# being the most profitable on average
MSize_median <- group_by(df, MarketSize) %>%
summarize(median = median(SalesInThousands))
MSize_mean <- group_by(df, MarketSize) %>%
summarize(mean = mean(SalesInThousands))
MSize_location <- as.tibble(cbind(MSize_median[,1], MSize_median[,2], MSize_mean[,2]))
MSize_location
# As a final step to discover hidden factors, we build a tree model
# With this information, we can move on to our predictive model
df_tree <- rpart(SalesInThousands ~ MarketSize + AgeOfStore + Promotion + week,
data = df, control = rpart.control(cp=.005))
plot(df_tree, uniform = TRUE, margin = .05)
text(df_tree)
# ---- RANDOM FOREST ------------------------------------------------------------------------- #
# Splitting the data into training and test sets
df
data(df)
n = nrow(df)
trainIndex = sample(1:n, size = round(0.7*n), replace=FALSE)
train = df[trainIndex ,]
test = df[-trainIndex ,]
############## As a first model, we try a random Forest
rf <- randomForest(SalesInThousands ~ MarketSize + AgeOfStore + Promotion + week,
data = train)
# First we have a look at how good our predictions were:
rf_pred <- predict(rf, test)
rf_test_pred <- tibble(values = test$SalesInThousands, predictions = rf_pred,
diff = test$SalesInThousands - rf_pred)
rf_test_pred
rf_diffplot <- tibble(values = rf_test_pred$values, error = rf_test_pred$diff,
cl = as.factor(test$MarketSize))
ggplot(rf_diffplot, aes(y = error, x = values, color = cl)) +
geom_point() +
geom_hline(yintercept = 0)
# We notice large errors for the groups "Large" and "Medium", while the estimation of
# the group "Small" tends to work better
# Finally we compute the RMSE
modelr::rmse(rf, data = df)
############## Since MarketSize seems to be the most influential variable, we should try a linear model
lmodel <- lm(SalesInThousands ~ MarketSize, data = train)
summary(lmodel)
# Now we look at how good our predictions were:
lm_pred <- predict(lmodel, test)
lm_test_pred <- tibble(values = test$SalesInThousands, predictions = lm_pred,
diff = test$SalesInThousands - lm_pred)
lm_test_pred
lm_diffplot <- tibble(values = lm_test_pred$values, error = lm_test_pred$diff,
cl = as.factor(test$MarketSize))
ggplot(lm_diffplot, aes(y = error, x = values, color = cl)) +
geom_point() +
geom_hline(yintercept = 0)
# These predictions also look far-off, so we compute the RMSE to check
modelr::rmse(lmodel, data = df)
# installing and loading dependencies
# install.packages("coin")
# install.packages("rpart")
# install.packages("cluster")
# install.packages("randomForest")
# install.packages("caret")
install.packages("FNN")
# installing and loading dependencies
# install.packages("coin")
# install.packages("rpart")
# install.packages("cluster")
# install.packages("randomForest")
# install.packages("caret")
# install.packages("FNN")
library(FNN)
?knn
train
knn_pred <- knn(train = train, test = test, cl = SalesInThousands, k = 5)
knn_pred <- knn(train = train, test = test, cl = test$SalesInThousands, k = 5)
knn_pred <- knn(train = train, test = test, cl = outcome, k = 5)
knn_pred <- knn(train = train, test = test, k = 5)
knn_pred <- knn(train = train, test = test, cl = MarketSize, k = 5)
knn_pred <- knn(train = train, test = test, cl = df$MarketSize, k = 5)
knn_pred <- knn(train = train, test = test, cl = train$MarketSize, k = 5)
knn_pred <- knn(train = train, test = test, cl = train$SalesInThousands, k = 5)
train_std <- scale(train)
